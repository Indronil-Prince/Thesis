{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import cv2\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math \n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    "    #for filename in filenames:\n",
    "       #os.path.join(dirname, filename)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35108"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\\\4-1\\\\Thesis\\\\resized_train_cropped\\\\trainLabels_cropped.csv\", header=None)\n",
    "df = df.iloc[1:]\n",
    "num = len(df)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_route = \"F:\\\\4-1\\\\Thesis\\\\resized_train_cropped\\\\resized_train_cropped\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def process_image(dfiloc: np.int64, imgloc: str):\n",
    "    img1 = cv2.imread(imgloc,1)\n",
    "    img1 = cv2.resize(img1, (350,350))\n",
    "    processed_image = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    return processed_image\n",
    "\n",
    "class_list=[]\n",
    "img=[]\n",
    "\n",
    "variables_config = {\n",
    "    '0': (0, 10),\n",
    "    '1': (0, 2),\n",
    "    '2': (0, 4)\n",
    "}\n",
    "\n",
    "for i in range(data_size):\n",
    "    imgloc = train_images_route + df.iloc[i,2] + '.jpeg'\n",
    "    df_location = df.iloc[i,3]\n",
    "    class_list.append(df_location)\n",
    "\n",
    "    if df_location not in variables_config:\n",
    "        img.append(process_image(df_location, imgloc))\n",
    "        continue\n",
    "    \n",
    "    variables_config[df_location][0] += 1\n",
    "    if variables_config[df_location][0] % variables_config[df_location][1] == 0:\n",
    "        img.append(process_image(df_location, imgloc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counted_variables = Counter(class_list)\n",
    "print(counted_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_size = len(class_list)\n",
    "new_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area_of_exudate=[]\n",
    "gre = []\n",
    "for image in img:\n",
    "    img2 = np.array(image)\n",
    "    r, greencha, b = cv2.split(img2)\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8)) \n",
    "    curImg = clahe.apply(greencha)\n",
    "    gre.append(curImg)\n",
    "    strEl = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(6,6))\n",
    "    curImg = cv2.dilate(curImg, strEl)\n",
    "    curImg = cv2.medianBlur(curImg,5)\n",
    "    retValue, curImg = cv2.threshold(curImg, 235, 255, cv2.THRESH_BINARY)\n",
    "    #curImg= cv2.cvtColor(curImg,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    rv2, optical_disk = cv2.threshold(b, 240, 255, cv2.THRESH_BINARY)\n",
    "    curImg = cv2.subtract(curImg,optical_disk)\n",
    "    \n",
    "    \n",
    "    moment = cv2.moments(curImg)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    "\n",
    "    #for i in range(0,7):\n",
    "    #    huMoments[i] = -1 * math.copysign(1.0, huMoments[i]) * np.log10(abs(huMoments[i]))\n",
    "    #Humoments2 = -np.sign(Humoments)*np.log10(np.abs(Humoments))\n",
    "    area_of_exudate.append(huMoments[0])\n",
    "    \n",
    "area_of_exudate = [y for x in area_of_exudate for y in x]\n",
    "print(area_of_exudate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_for_bv = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "def extract_bv(image):\n",
    "\n",
    "    contrast_enhanced_green_fundus = image\n",
    "   \n",
    "    r1 = cv2.morphologyEx(contrast_enhanced_green_fundus, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 1)\n",
    "    R1 = cv2.morphologyEx(r1, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 1)\n",
    "    r2 = cv2.morphologyEx(R1, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)), iterations = 1)\n",
    "   \n",
    "    R2 = cv2.morphologyEx(r2, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)), iterations = 1)\n",
    "   \n",
    "    r3 = cv2.morphologyEx(R2, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(23,23)), iterations = 1)\n",
    "    \n",
    "    R3 = cv2.morphologyEx(r3, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(23,23)), iterations = 1)\n",
    "   # cv2.imshow('contrast_enhanced_green_fundus',contrast_enhanced_green_fundus)\n",
    "    f4 = cv2.subtract(R3,contrast_enhanced_green_fundus)\n",
    "    f5 = clahe.apply(f4)\n",
    "   # cv2.imshow('f5',f5)\n",
    "    ret,f6 = cv2.threshold(f5,15,255,cv2.THRESH_BINARY)\n",
    "    mask = np.ones(f5.shape[:2], dtype=\"uint8\") * 255\n",
    "    #print(mask)\n",
    "   # _, contours, _ = cv2.findContours(f6.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(f6.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) <= 200:\n",
    "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "            \n",
    "    im = cv2.bitwise_and(f5, f5, mask=mask)\n",
    "    ret, fin = cv2.threshold(im, 15, 255, cv2.THRESH_BINARY_INV)\n",
    "    newfin = cv2.erode(fin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations=1)\n",
    "\n",
    "   \n",
    "    fundus_eroded = cv2.bitwise_not(newfin) \n",
    "    xmask = np.ones(image.shape[:2], dtype=\"uint8\") * 255\n",
    "    xcontours, xhierarchy = cv2.findContours(fundus_eroded.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    for cnt in xcontours:\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.04 * peri, False)\n",
    "        if len(approx) > 4 and cv2.contourArea(cnt) <= 3000 and cv2.contourArea(cnt) >= 100:\n",
    "            shape = \"circle\"\n",
    "        else:\n",
    "            shape = \"veins\"\n",
    "        if(shape==\"circle\"):\n",
    "            cv2.drawContours(xmask, [cnt], -1, 0, -1)\n",
    "\n",
    "    finimage = cv2.bitwise_and(fundus_eroded,fundus_eroded,mask=xmask)\n",
    "    blood_vessels = cv2.bitwise_not(finimage)\n",
    "    return blood_vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_bloodvessel = []\n",
    "image_size = (350, 350)\n",
    "\n",
    "for image in gre:\n",
    "    bloodvessel = extract_bv(image)\n",
    "    bloodvessel = cv2.resize(bloodvessel, image_size)\n",
    "    count = 0\n",
    "    bloodvessel = 255 - bloodvessel\n",
    "    retValue, bloodvessel = cv2.threshold(bloodvessel, 235, 255, cv2.THRESH_BINARY)\n",
    "    bloodvessel = cv2.dilate(bloodvessel,kernel_for_bv,iterations=1)\n",
    "    \n",
    "    moment = cv2.moments(bloodvessel)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    " \n",
    "    area_of_bloodvessel.append(huMoments[0])\n",
    "    \n",
    "area_of_bloodvessel = [y for x in area_of_bloodvessel for y in x]\n",
    "print(area_of_bloodvessel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelmicro = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ma(image):\n",
    "     \n",
    "    median = cv2.medianBlur(image,3)\n",
    "\n",
    "    erosion_ma = 255 - cv2.erode(median, kernelmicro,iterations=1)\n",
    "    ret3,thresh2 = cv2.threshold(erosion_ma,215,255,cv2.THRESH_BINARY)\n",
    "    closing_ma = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernelmicro)\n",
    "    mask = np.ones(closing_ma.shape[:2], dtype=\"uint8\") * 255\n",
    "    contours_mn, hierarchy_mn = cv2.findContours(closing_ma, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "   \n",
    "    for cnt_mn in contours_mn:\n",
    "        if cv2.contourArea(cnt_mn) <= 70:\n",
    "            cv2.drawContours(mask, [cnt_mn], -1, 0, -1)\n",
    "            \n",
    "    final_ma = cv2.bitwise_and(closing_ma, closing_ma, mask=mask)\n",
    "    sub_ma = cv2.subtract(closing_ma,final_ma)\n",
    "    sub_ma = cv2.morphologyEx(sub_ma, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)\n",
    "    sub_ma =cv2.erode(sub_ma,kernelmicro,iterations=1)\n",
    "    return sub_ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_micro = []\n",
    "for image in gre:\n",
    "    count = 0\n",
    "    mcran = extract_ma(image)\n",
    "    \n",
    "    moment = cv2.moments(mcran)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    "    area_of_micro.append(huMoments[0])\n",
    "\n",
    "area_of_micro = [y for x in area_of_micro for y in x]\n",
    "print(area_of_micro)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(area_of_exudate,area_of_bloodvessel, area_of_micro))\n",
    "y = class_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_config = {\n",
    "    'test_size': .25,\n",
    "    'random_state': 0\n",
    "}\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, **train_config)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_config = {\n",
    "    'n_estimators': 3000,\n",
    "    'criterion': 'gini',\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': 1,\n",
    "    'oob_score': True\n",
    "}\n",
    "Classifier = RandomForestClassifier(**classifier_config)\n",
    "Classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_data import plot_using_plt, plot_using_plotly\n",
    "\n",
    "class_list = pd.to_numeric(class_list)\n",
    "colors = class_list\n",
    "\n",
    "x = area_of_bloodvessel\n",
    "y = area_of_exudate\n",
    "z = area_of_micro\n",
    "\n",
    "plot_using_plt(x, y, z, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = area_of_bloodvessel\n",
    "y = area_of_micro\n",
    "z = area_of_exudate\n",
    "\n",
    "plot_using_plotly(x, y, z, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
