{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import cv2\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import math \n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    "    #for filename in filenames:\n",
    "       #os.path.join(dirname, filename)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35108"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"F:\\\\4-1\\\\Thesis\\\\resized_train_cropped\\\\trainLabels_cropped.csv\", header=None)\n",
    "df = df.iloc[1:]\n",
    "num = len(df)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size= num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"F:\\\\4-1\\\\Thesis\\\\resized_train_cropped\\\\resized_train_cropped\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class_list=[]\n",
    "img=[]\n",
    "two_cnt=0\n",
    "one_cnt=0\n",
    "zero_cnt=0\n",
    "for i in range(0,data_size):\n",
    "    imgloc = s+df.iloc[i,2]+'.jpeg'\n",
    "    if(df.iloc[i,3]=='0'):\n",
    "        zero_cnt=zero_cnt+1\n",
    "        if(zero_cnt%10==0):\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            img1 = cv2.imread(imgloc,1)\n",
    "            img1 = cv2.resize(img1,(350,350))\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            #img1 = cv2.flip(img1,1)\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "    elif(df.iloc[i,3]=='2'):\n",
    "        two_cnt=two_cnt+1\n",
    "        if(two_cnt%4==0):    \n",
    "            class_list.append(df.iloc[i,3])\n",
    "            img1 = cv2.imread(imgloc,1)\n",
    "            img1 = cv2.resize(img1,(350,350))\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            #img1 = cv2.flip(img1,1)\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "    elif(df.iloc[i,3]=='1'):\n",
    "        one_cnt=one_cnt+1\n",
    "        if(one_cnt%2==0):    \n",
    "            class_list.append(df.iloc[i,3])\n",
    "            img1 = cv2.imread(imgloc,1)\n",
    "            img1 = cv2.resize(img1,(350,350))\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            #img1 = cv2.flip(img1,1)\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            img1 = cv2.imread(imgloc,1)\n",
    "            img1 = cv2.resize(img1,(350,350))\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))\n",
    "            class_list.append(df.iloc[i,3])\n",
    "            #img1 = cv2.flip(img1,1)\n",
    "            img.append(cv2.cvtColor(img1,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[3]=pd.to_numeric(df[3])\n",
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "four = 0\n",
    "for i in range(0,len(class_list)):\n",
    "    if(class_list[i]=='0'): zero= zero+1\n",
    "    elif(class_list[i]=='1'): one= one+1\n",
    "    elif(class_list[i]=='2'): two= two+1\n",
    "    elif(class_list[i]=='3'): three= three+1\n",
    "    elif(class_list[i]=='4'): four= four+1\n",
    "print(zero, one, two, three, four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_size=len(class_list)\n",
    "new_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "area_of_exudate=[]\n",
    "gre = []\n",
    "for i in range(0,new_data_size):\n",
    "    img2 = np.array(img[i])\n",
    "    r,greencha,b=cv2.split(img2)\n",
    "    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8)) \n",
    "    curImg = clahe.apply(greencha)\n",
    "    gre.append(curImg)\n",
    "    strEl = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(6,6))\n",
    "    curImg = cv2.dilate(curImg, strEl)\n",
    "    curImg = cv2.medianBlur(curImg,5)\n",
    "    retValue, curImg = cv2.threshold(curImg, 235, 255, cv2.THRESH_BINARY)\n",
    "    #curImg= cv2.cvtColor(curImg,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    rv2, optical_disk = cv2.threshold(b, 240, 255, cv2.THRESH_BINARY)\n",
    "    curImg = cv2.subtract(curImg,optical_disk)\n",
    "    \n",
    "    \n",
    "    moment = cv2.moments(curImg)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    "\n",
    "    #for i in range(0,7):\n",
    "    #    huMoments[i] = -1 * math.copysign(1.0, huMoments[i]) * np.log10(abs(huMoments[i]))\n",
    "    #Humoments2 = -np.sign(Humoments)*np.log10(np.abs(Humoments))\n",
    "    area_of_exudate.append(huMoments[0])\n",
    "flattened_list = [y for x in area_of_exudate for y in x]\n",
    "#flattened_list = np.shape(flattened_list)\n",
    "area_of_exudate = flattened_list\n",
    "print(area_of_exudate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_for_bv = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "def extract_bv(image):\n",
    "\n",
    "    contrast_enhanced_green_fundus = image\n",
    "   \n",
    "    r1 = cv2.morphologyEx(contrast_enhanced_green_fundus, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 1)\n",
    "    R1 = cv2.morphologyEx(r1, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)), iterations = 1)\n",
    "    r2 = cv2.morphologyEx(R1, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)), iterations = 1)\n",
    "   \n",
    "    R2 = cv2.morphologyEx(r2, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)), iterations = 1)\n",
    "   \n",
    "    r3 = cv2.morphologyEx(R2, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(23,23)), iterations = 1)\n",
    "    \n",
    "    R3 = cv2.morphologyEx(r3, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(23,23)), iterations = 1)\n",
    "   # cv2.imshow('contrast_enhanced_green_fundus',contrast_enhanced_green_fundus)\n",
    "    f4 = cv2.subtract(R3,contrast_enhanced_green_fundus)\n",
    "    f5 = clahe.apply(f4)\n",
    "   # cv2.imshow('f5',f5)\n",
    "    ret,f6 = cv2.threshold(f5,15,255,cv2.THRESH_BINARY)\n",
    "    mask = np.ones(f5.shape[:2], dtype=\"uint8\") * 255\n",
    "    #print(mask)\n",
    "   # _, contours, _ = cv2.findContours(f6.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(f6.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) <= 200:\n",
    "            cv2.drawContours(mask, [cnt], -1, 0, -1)\n",
    "    im = cv2.bitwise_and(f5, f5, mask=mask)\n",
    "    ret,fin = cv2.threshold(im,15,255,cv2.THRESH_BINARY_INV)\n",
    "    newfin = cv2.erode(fin, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations=1)\n",
    "\n",
    "   \n",
    "    fundus_eroded = cv2.bitwise_not(newfin) \n",
    "    xmask = np.ones(image.shape[:2], dtype=\"uint8\") * 255\n",
    "    xcontours, xhierarchy = cv2.findContours(fundus_eroded.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    for cnt in xcontours:\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.04 * peri, False)\n",
    "        if len(approx) > 4 and cv2.contourArea(cnt) <= 3000 and cv2.contourArea(cnt) >= 100:\n",
    "            shape = \"circle\"\n",
    "        else:\n",
    "            shape = \"veins\"\n",
    "        if(shape==\"circle\"):\n",
    "            cv2.drawContours(xmask, [cnt], -1, 0, -1)\n",
    "\n",
    "    finimage = cv2.bitwise_and(fundus_eroded,fundus_eroded,mask=xmask)\n",
    "    blood_vessels = cv2.bitwise_not(finimage)\n",
    "    return blood_vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_bloodvessel=[]\n",
    "\n",
    "for i in range(0,new_data_size):\n",
    "    bloodvessel = extract_bv(gre[i])\n",
    "    bloodvessel = cv2.resize(bloodvessel,(350,350))\n",
    "    count = 0\n",
    "    bloodvessel =255- bloodvessel\n",
    "    retValue, bloodvessel = cv2.threshold(bloodvessel, 235, 255, cv2.THRESH_BINARY)\n",
    "    bloodvessel = cv2.dilate(bloodvessel,kernel_for_bv,iterations = 1)\n",
    "   # bloodvessel= cv2.cvtColor(bloodvessel,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    moment = cv2.moments(bloodvessel)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    "\n",
    "  #  for i in range(0,7):\n",
    "  #      huMoments[i] = -1 * math.copysign(1.0, huMoments[i]) * np.log10(abs(huMoments[i]))\n",
    " \n",
    "    area_of_bloodvessel.append(huMoments[0])\n",
    "flattened_list = [y for x in area_of_bloodvessel for y in x]\n",
    "#flattened_list = np.shape(flattened_list)\n",
    "area_of_bloodvessel = flattened_list\n",
    "\n",
    "print(area_of_bloodvessel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelmicro = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ma(image):\n",
    "     \n",
    "    median = cv2.medianBlur(image,3)\n",
    "\n",
    "    erosion_ma =255- cv2.erode(median, kernelmicro,iterations = 1)\n",
    "    ret3,thresh2 = cv2.threshold(erosion_ma,215,255,cv2.THRESH_BINARY)\n",
    "    closing_ma = cv2.morphologyEx(thresh2, cv2.MORPH_CLOSE, kernelmicro)\n",
    "    mask = np.ones(closing_ma.shape[:2], dtype=\"uint8\") * 255\n",
    "    contours_mn, hierarchy_mn = cv2.findContours(closing_ma, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "   \n",
    "    for cnt_mn in contours_mn:\n",
    "        if cv2.contourArea(cnt_mn) <= 70:\n",
    "            cv2.drawContours(mask, [cnt_mn], -1, 0, -1)\n",
    "    final_ma = cv2.bitwise_and(closing_ma, closing_ma, mask=mask)\n",
    "    sub_ma = cv2.subtract(closing_ma,final_ma)\n",
    "    sub_ma = cv2.morphologyEx(sub_ma, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)), iterations = 1)\n",
    "    sub_ma =cv2.erode(sub_ma,kernelmicro,iterations = 1)\n",
    "    return sub_ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_micro = []\n",
    "for i in range(0,new_data_size):\n",
    "    count = 0\n",
    "    mcran = extract_ma(gre[i])\n",
    "    \n",
    "    moment = cv2.moments(mcran)\n",
    "    huMoments = cv2.HuMoments(moment)\n",
    "\n",
    "  #  for i in range(0,7):\n",
    "  #      huMoments[i] = -1 * math.copysign(1.0, huMoments[i]) * np.log10(abs(huMoments[i]))\n",
    " \n",
    "    area_of_micro.append(huMoments[0])\n",
    "    \n",
    "flattened_list = [y for x in area_of_micro for y in x]\n",
    "#flattened_list = np.shape(flattened_list)\n",
    "area_of_micro = flattened_list\n",
    "print(area_of_micro)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(area_of_exudate,area_of_bloodvessel,area_of_micro))\n",
    "print(len(X))\n",
    "y = class_list\n",
    "#df.iloc[0:new_data_size,3:4].values\n",
    "#print((y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = .25 ,random_state =0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Classifier = RandomForestClassifier(n_estimators = 3000, criterion='gini', max_features = 'sqrt',  random_state=1, oob_score=True)\n",
    "Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize = (16,16))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "class_list=pd.to_numeric(class_list)\n",
    "\n",
    "z_points = area_of_micro\n",
    "x_points = area_of_bloodvessel\n",
    "y_points = area_of_exudate\n",
    "ax.scatter3D(x_points, y_points, z_points, zdir=x_points, c=class_list, cmap=cm.Set1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(x=area_of_bloodvessel, y=area_of_micro, z=area_of_exudate,\n",
    "              color=class_list)\n",
    "fig.update_traces(marker=dict(size=2,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
